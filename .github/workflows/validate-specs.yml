name: Validate Specifications---

name: Validate Specifications

on:

  pull_request:"on":

    paths:  pull_request:

      - 'specs/**'    paths:

      - 'features/**/*.feature'      - 'specs/**'

      - 'templates/**'      - '**/*.feature'

  push:      - 'requirements/**'

    branches: [ main ]

    paths:jobs:

      - 'specs/**'  validate-specs:

      - 'features/**/*.feature'    runs-on: ubuntu-latest

      - 'templates/**'    steps:

  workflow_dispatch:      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5

jobs:        with:

  validate:          python-version: '3.11'

    name: Validate ${{ matrix.spec-type }}

    runs-on: ubuntu-latest      - name: Install dependencies

    strategy:        run: |

      fail-fast: false          pip install behave gherkin-lint pyyaml jsonschema

      matrix:

        python-version: ['3.9', '3.10', '3.11']      - name: Validate BDD syntax

        spec-type: ['features', 'openapi', 'protobuf']        run: |

        include:          for file in $(find . -name "*.feature"); do

          - spec-type: 'features'            echo "Validating $file..."

            validate-script: 'validate_features.py'            behave --dry-run "$file" || true

            spec-path: 'features/**/*.feature'          done

          - spec-type: 'openapi'

            validate-script: 'validate_openapi.py'      - name: Check spec coverage

            spec-path: 'specs/openapi/**/*.yaml'        run: |

          - spec-type: 'protobuf'          python3 - <<'PY'

            validate-script: 'validate_protobuf.py'          import os

            spec-path: 'specs/proto/**/*.proto'          import json

          from pathlib import Path

    steps:

    - uses: actions/checkout@v4          def analyze_spec_coverage():

              issues = []

    - name: Set up Python ${{ matrix.python-version }}              total_scenarios = 0

      uses: actions/setup-python@v4              implemented = 0

      with:

        python-version: ${{ matrix.python-version }}              for feature_file in Path('.').rglob('*.feature'):

        cache: 'pip'                  with open(feature_file) as f:

                      content = f.read()

    - name: Install dependencies                      scenarios = content.count('Scenario:')

      run: |                      total_scenarios += scenarios

        python -m pip install --upgrade pip

        pip install -r requirements.txt                      lines = content.splitlines()

        pip install -r patch_requirements.txt                      for i, line in enumerate(lines, 1):

                          if line.strip().startswith('Scenario:'):

    - name: Validate ${{ matrix.spec-type }} specs                              has_given = False

      run: |                              has_when = False

        python scripts/${{ matrix.validate-script }} \                              has_then = False

          --spec-path "${{ matrix.spec-path }}" \                              for step in lines[i:i+10]:

          --report-path "reports/${{ matrix.spec-type }}-validation.json"                                  if step.strip().startswith('Given '):

                                      has_given = True

    - name: Check specification coverage                                  elif step.strip().startswith('When '):

      run: |                                      has_when = True

        python scripts/validate_spec_coverage.py \                                  elif step.strip().startswith('Then '):

          --spec-type "${{ matrix.spec-type }}" \                                      has_then = True

          --coverage-threshold 90                              if not (has_given and has_when and has_then):

                                  issues.append({

    - name: Upload validation report                                      'file': str(feature_file),

      uses: actions/upload-artifact@v3                                      'line': i,

      with:                                      'issue': 'Incomplete scenario steps'

        name: validation-report-${{ matrix.spec-type }}                                  })

        path: reports/${{ matrix.spec-type }}-validation.json                              else:

        retention-days: 7                                  implemented += 1

              report = {
                  'spec_coverage': round(
                      (implemented / total_scenarios * 100)
                      if total_scenarios > 0 else 0,
                      2
                  ),
                  'total_scenarios': total_scenarios,
                  'implemented_scenarios': implemented,
                  'errors': issues
              }

              os.makedirs('reports', exist_ok=True)
              with open('reports/spec-coverage.json', 'w') as f:
                  json.dump(report, f, indent=2)

              if issues:
                  print('❌ Specification validation failed!')
                  print(f'Found {len(issues)} issues:')
                  for issue in issues:
                      print(
                          f"- {issue['file']}:{issue['line']} - "
                          f"{issue['issue']}"
                      )
                  with open('reports/spec-validation-failed','w') as m:
                      m.write('failed')
                  raise SystemExit(1)
              else:
                  print('✅ All specifications are valid!')
                  print(f"Coverage: {report['spec_coverage']}%")
                  print(f"Total scenarios: {total_scenarios}")
                  print(f"Implemented: {implemented}")

          if __name__ == '__main__':
              analyze_spec_coverage()
          PY

      - name: Upload spec coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: spec-coverage-report
          path: reports/spec-coverage.json
